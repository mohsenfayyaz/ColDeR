{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6c209a-5118-4aa4-b8a4-2c11a73c3102",
   "metadata": {},
   "source": [
    "# BEIR: A Heterogenous benchmark for Zero-shot Evaluation of Information Retrieval models\n",
    "\n",
    "This notebook contains an simple and easy examples to evaluate retrieval models from our new benchmark.\n",
    "\n",
    "## Introduction\n",
    "The BEIR benchmark contains 9 diverse retrieval tasks including 17 diverse datasets. We evaluate 9 state-of-the-art retriever models all in a zero-shot evaluation setup. Today, in this colab notebook, we first will show how to download and load the 14 open-sourced datasets with just three lines of code. Afterward, we would load some state-of-the-art dense retrievers (bi-encoders) such as SBERT, ANCE, DPR models and use them for retrieval and evaluate them in a zero-shot setup.\n",
    "\n",
    "Don't hesitate to send us an e-mail or report an issue, if something is broken (and it shouldn't be) or if you have further questions.\n",
    "\n",
    "Developed by Nandan Thakur, Researcher @ UKP Lab, TU Darmstadt\n",
    "\n",
    "(https://nthakur.xyz) (nandant@gmail.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb1c6e6-2402-4080-b3e2-45c74d3fa265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES: 3 HF_HOME: /local1/mohsenfayyaz/.hfcache/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "print(\"CUDA_VISIBLE_DEVICES:\", os.environ[\"CUDA_VISIBLE_DEVICES\"], \"HF_HOME:\", os.environ[\"HF_HOME\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad8a3ea-7fc7-4409-b59f-0ed5861cc9d0",
   "metadata": {},
   "source": [
    "# Install BEIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614fa33f-2006-45bb-99ac-ebf984eebfd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip install beir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a3c543-d5b9-4296-b122-f0457c38eca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local1/mohsenfayyaz/anaconda3/envs/beir-env/lib/python3.11/site-packages/beir/util.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from beir import util, LoggingHandler\n",
    "import logging\n",
    "import pathlib, os\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "#### /print debug information to stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da54665-38cf-490b-8044-93daccd2fe06",
   "metadata": {},
   "source": [
    "**BEIR Datasets**\n",
    "\n",
    "BEIR contains 17 diverse datasets overall. You can view all the datasets (14 downloadable) with the link below:\n",
    "\n",
    "[``https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/``](https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/)\n",
    "\n",
    "Please refer GitHub page to evaluate on other datasets (3 of them).\n",
    "\n",
    "\n",
    "We include the following datasets in BEIR:\n",
    "\n",
    "| Dataset   | Website| BEIR-Name | Domain     | Relevancy| Queries  | Documents | Avg. Docs/Q | Download |\n",
    "| -------- | -----| ---------| ----------- | ---------| ---------| --------- | ------| ------------|\n",
    "| MSMARCO    | [``Homepage``](https://microsoft.github.io/msmarco/)| ``msmarco`` | Misc.       |  Binary  |  6,980   |  8.84M     |    1.1 | Yes |  \n",
    "| TREC-COVID |  [``Homepage``](https://ir.nist.gov/covidSubmit/index.html)| ``trec-covid``| Bio-Medical |  3-level|50|  171K| 493.5 | Yes |\n",
    "| NFCorpus   | [``Homepage``](https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/) | ``nfcorpus``  | Bio-Medical |  3-level |  323     |  3.6K     |  38.2 | Yes |\n",
    "| BioASQ     | [``Homepage``](http://bioasq.org) | ``bioasq``| Bio-Medical |  Binary  |   500    |  14.91M    |  8.05 | No |\n",
    "| NQ         | [``Homepage``](https://ai.google.com/research/NaturalQuestions) | ``nq``| Wikipedia   |  Binary  |  3,452   |  2.68M  |  1.2 | Yes |\n",
    "| HotpotQA   | [``Homepage``](https://hotpotqa.github.io) | ``hotpotqa``| Wikipedia   |  Binary  |  7,405   |  5.23M  |  2.0 | Yes |\n",
    "| FiQA-2018  | [``Homepage``](https://sites.google.com/view/fiqa/) | ``fiqa``    | Finance     |  Binary  |  648     |  57K    |  2.6 | Yes |\n",
    "| Signal-1M (RT) | [``Homepage``](https://research.signal-ai.com/datasets/signal1m-tweetir.html)| ``signal1m`` | Twitter     |  3-level  |   97   |  2.86M  |  19.6 | No |\n",
    "| TREC-NEWS  | [``Homepage``](https://trec.nist.gov/data/news2019.html) | ``trec-news``    | News     |  5-level  |   57    |  595K    |  19.6 | No |\n",
    "| ArguAna    | [``Homepage``](http://argumentation.bplaced.net/arguana/data) | ``arguana`` | Misc.       |  Binary  |  1,406     |  8.67K    |  1.0 | Yes |\n",
    "| Touche-2020| [``Homepage``](https://webis.de/events/touche-20/shared-task-1.html) | ``webis-touche2020``| Misc.       |  6-level  |  49     |  382K    |  49.2 |  Yes |\n",
    "| CQADupstack| [``Homepage``](http://nlp.cis.unimelb.edu.au/resources/cqadupstack/) | ``cqadupstack``| StackEx.      |  Binary  |  13,145 |  457K  |  1.4 |  Yes |\n",
    "| Quora| [``Homepage``](https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs) | ``quora``| Quora  | Binary  |  10,000     |  523K    |  1.6 |  Yes |\n",
    "| DBPedia | [``Homepage``](https://github.com/iai-group/DBpedia-Entity/) | ``dbpedia-entity``| Wikipedia |  3-level  |  400    |  4.63M    |  38.2 |  Yes |\n",
    "| SCIDOCS| [``Homepage``](https://allenai.org/data/scidocs) | ``scidocs``| Scientific |  Binary  |  1,000     |  25K    |  4.9 |  Yes |\n",
    "| FEVER| [``Homepage``](http://fever.ai) | ``fever``| Wikipedia     |  Binary  |  6,666     |  5.42M    |  1.2|  Yes |\n",
    "| Climate-FEVER| [``Homepage``](http://climatefever.ai) | ``climate-fever``| Wikipedia |  Binary  |  1,535     |  5.42M |  3.0 |  Yes |\n",
    "| SciFact| [``Homepage``](https://github.com/allenai/scifact) | ``scifact``| Scientific |  Binary  |  300     |  5K    |  1.1 |  Yes |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b8bd7a-29fe-494b-b8e7-babae2d49753",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a470deb-777e-4cbd-a74f-02f0482d8f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded here: /local1/mohsenfayyaz/projects/Retriever-Contextualization/src/notebooks/datasets/nq\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"nq\"\n",
    "\n",
    "# ! git lfs install\n",
    "\n",
    "# ! git clone https://huggingface.co/datasets/BeIR/nq\n",
    "# ! mkdir --parents ./datasets/; \n",
    "# ! mv nq datasets/\n",
    "# ! gzip -d datasets/nq/corpus.jsonl.gz\n",
    "# ! gzip -d datasets/nq/queries.jsonl.gz\n",
    "\n",
    "# ! git clone https://huggingface.co/datasets/BeIR/nq-qrels\n",
    "# ! mv nq-qrels datasets/nq/qrels\n",
    "\n",
    "### SLOW\n",
    "import pathlib, os\n",
    "from beir import util\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(DATASET)\n",
    "out_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "data_path = util.download_and_unzip(url, out_dir)\n",
    "print(\"Dataset downloaded here: {}\".format(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ff2d13-4df0-44a8-95bb-31b89124b6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-20 15:11:27 - Loading Corpus...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2ff3c7264e44bcb20b465e63ea2bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2681468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-20 15:11:40 - Loaded 2681468 TEST Documents.\n",
      "2024-08-20 15:11:40 - Doc Example: {'text': \"In accounting, minority interest (or non-controlling interest) is the portion of a subsidiary corporation's stock that is not owned by the parent corporation. The magnitude of the minority interest in the subsidiary company is generally less than 50% of outstanding shares, or the corporation would generally cease to be a subsidiary of the parent.[1]\", 'title': 'Minority interest'}\n",
      "2024-08-20 15:11:40 - Loading Queries...\n",
      "2024-08-20 15:11:40 - Loaded 3452 TEST Queries.\n",
      "2024-08-20 15:11:40 - Query Example: what is non controlling interest on balance sheet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22d884bc76c44798bd30f9dbab6f474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3452 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'#Corpus:': 2681468, '#Gold_Corpus:': 4201, '#Queries&qrels:': 3452}\n"
     ]
    }
   ],
   "source": [
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "data_path = f\"datasets/{DATASET}\"\n",
    "corpus_raw, queries, qrels = GenericDataLoader(data_path).load(split=\"test\") # or split = \"train\" or \"dev\"\n",
    "\n",
    "gold_docs = set()\n",
    "for test_k, test_v in tqdm(qrels.items()):\n",
    "    for doc_k, doc_v in test_v.items():\n",
    "        gold_docs.add(doc_k)\n",
    "print({\n",
    "    \"#Corpus:\": len(corpus_raw), \n",
    "    \"#Gold_Corpus:\": len(gold_docs),\n",
    "    \"#Queries&qrels:\": len(queries)\n",
    "})\n",
    "corpus = {d: corpus_raw[d] for d in gold_docs}  # corpus = raw_corpus  (FOR GOLD OR ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5902e4d8-c47e-431f-95a3-7bc17b6705b5",
   "metadata": {},
   "source": [
    "# **Dense Retrieval using Exact Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75161274-084d-4ddc-be82-e8acde408956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-20 15:11:42 - PyTorch version 2.4.0 available.\n",
      "2024-08-20 15:11:42 - Loading faiss with AVX2 support.\n",
      "2024-08-20 15:11:42 - Successfully loaded faiss with AVX2 support.\n",
      "2024-08-20 15:11:42 - Use pytorch device_name: cuda\n",
      "2024-08-20 15:11:42 - Load pretrained SentenceTransformer: facebook/contriever-msmarco\n",
      "2024-08-20 15:11:42 - No sentence-transformers model found with name facebook/contriever-msmarco. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local1/mohsenfayyaz/anaconda3/envs/beir-env/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-20 15:11:44 - Encoding Queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ef736e85b2499eb5cee53c0d5e51ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-20 15:11:45 - Sorting Corpus by document length (Longest first)...\n",
      "2024-08-20 15:11:45 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-08-20 15:11:45 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-08-20 15:11:45 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7155feaeded84c96a81bcad4aef001a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval import models\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "\n",
    "#### Dense Retrieval using SBERT (Sentence-BERT) ####\n",
    "#### Provide any pretrained sentence-transformers model\n",
    "#### The model was fine-tuned using cosine-similarity.\n",
    "#### Complete list - https://www.sbert.net/docs/pretrained_models.html\n",
    "\n",
    "MODEL = \"facebook/contriever-msmarco\"  # \"msmarco-distilbert-base-v3\"\n",
    "model = DRES(models.SentenceBERT(MODEL), batch_size=128)\n",
    "retriever = EvaluateRetrieval(model, score_function=\"cos_sim\")\n",
    "\n",
    "#### Retrieve dense results (format of results is identical to qrels)\n",
    "results = retriever.retrieve(corpus, queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "948d609e-54d0-435c-aec1-412d8eb3b1ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results[\"test0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9696b531-910b-4048-b899-041e9d4e38e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-20 15:22:54 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-08-20 15:22:54 - For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2024-08-20 15:22:55 - \n",
      "\n",
      "2024-08-20 15:22:55 - NDCG@1: 0.9076\n",
      "2024-08-20 15:22:55 - NDCG@3: 0.9378\n",
      "2024-08-20 15:22:55 - NDCG@5: 0.9453\n",
      "2024-08-20 15:22:55 - NDCG@10: 0.9501\n",
      "2024-08-20 15:22:55 - NDCG@100: 0.9518\n",
      "2024-08-20 15:22:55 - NDCG@1000: 0.9522\n",
      "2024-08-20 15:22:55 - \n",
      "\n",
      "2024-08-20 15:22:55 - MAP@1: 0.8138\n",
      "2024-08-20 15:22:55 - MAP@3: 0.9266\n",
      "2024-08-20 15:22:55 - MAP@5: 0.9322\n",
      "2024-08-20 15:22:55 - MAP@10: 0.9346\n",
      "2024-08-20 15:22:55 - MAP@100: 0.9351\n",
      "2024-08-20 15:22:55 - MAP@1000: 0.9351\n",
      "2024-08-20 15:22:55 - \n",
      "\n",
      "2024-08-20 15:22:55 - Recall@1: 0.8138\n",
      "2024-08-20 15:22:55 - Recall@3: 0.9596\n",
      "2024-08-20 15:22:55 - Recall@5: 0.9762\n",
      "2024-08-20 15:22:55 - Recall@10: 0.9897\n",
      "2024-08-20 15:22:55 - Recall@100: 0.9974\n",
      "2024-08-20 15:22:55 - Recall@1000: 0.9999\n",
      "2024-08-20 15:22:55 - \n",
      "\n",
      "2024-08-20 15:22:55 - P@1: 0.9076\n",
      "2024-08-20 15:22:55 - P@3: 0.3867\n",
      "2024-08-20 15:22:55 - P@5: 0.2370\n",
      "2024-08-20 15:22:55 - P@10: 0.1203\n",
      "2024-08-20 15:22:55 - P@100: 0.0121\n",
      "2024-08-20 15:22:55 - P@1000: 0.0012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Recall@1': 0.81383,\n",
       " 'Recall@3': 0.95959,\n",
       " 'Recall@5': 0.97625,\n",
       " 'Recall@10': 0.98972,\n",
       " 'Recall@100': 0.99744,\n",
       " 'Recall@1000': 0.9999}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Evaluate your retrieval using NDCG@k, MAP@K ...\n",
    "\n",
    "logging.info(\"Retriever evaluation for k in: {}\".format(retriever.k_values))\n",
    "ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e1fda6-3c94-42c9-a1b0-d9eb78bdc790",
   "metadata": {},
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ccc690-b9e9-4fba-b665-68cdf486670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "load_dotenv()\n",
    "login(os.environ[\"HF_API_TOKEN\"])\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "# df = pd.read_json(\"hf://datasets/mohsenfayyaz/misc/res_triviaqa_test_w_gs.jsonl\", lines=True)\n",
    "# df.to_json(\"./res_triviaqa_test_w_gs.jsonl\", lines=True, orient=\"records\")\n",
    "\n",
    "df_dict = []\n",
    "sorted_results = {k: dict(sorted(v.items(), key=lambda item: item[1], reverse=True)) for k, v in results.items()}\n",
    "for key in tqdm(sorted_results.keys()):\n",
    "    df_dict.append({\n",
    "        \"key\": key,\n",
    "        \"query\": queries[key],\n",
    "        \"gold_docs\": [k for k, v in qrels[key].items()],\n",
    "        \"gold_docs_text\": [corpus[k] for k, v in qrels[key].items()],\n",
    "        \"results\": sorted_results[key],\n",
    "        \"predicted_docs_text_5\": [corpus[k] for k, v in dict(list(sorted_results[key].items())[:5]).items()],\n",
    "    })\n",
    "df = pd.DataFrame(df_dict)\n",
    "df.attrs['model'] = MODEL\n",
    "df.attrs['dataset'] = DATASET\n",
    "df.attrs['corpus_size'] = len(corpus)\n",
    "df.attrs['eval'] = {\"ndcg\": ndcg, \"map\": _map, \"recall\": recall, \"precision\": precision}\n",
    "print(df.attrs)\n",
    "hf_path = f\"hf://datasets/Retriever-Contextualization/datasets/{DATASET}/{MODEL.replace('/', '--')}_corpus{len(corpus)}.parquet\"\n",
    "df.to_parquet(hf_path)\n",
    "print(\"UPLOADED:\", hf_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e9ea9b-d92b-4c7a-97d8-2cc45d281188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qrels[\"test0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c5c274-3c82-4699-a99e-4566f8fa8d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
